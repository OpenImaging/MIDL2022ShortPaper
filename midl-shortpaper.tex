\documentclass{midl} % Include author names
%\documentclass[anon]{midl} % Anonymized submission

% The following packages will be automatically loaded:
% jmlr, amsmath, amssymb, natbib, graphicx, url, algorithm2e
% ifoddpage, relsize and probably more
% make sure they are installed with your latex distribution

\usepackage{mwe} % to get dummy images

% Header for extended abstracts
\jmlrproceedings{MIDL}{Medical Imaging with Deep Learning}
\jmlrpages{}
\jmlryear{2022}

% to be uncommented for submissions under review
\jmlrworkshop{Short Paper -- MIDL 2022 submission}
\jmlrvolume{-- Under Review}
\editors{Under Review for MIDL 2022}

\title[Medical Image Quality Assurance using Deep Learning]{Medical Image Quality Assurance using Deep Learning}

 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % Two authors with the same address
 % \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\and
 %  \Name{Author Name2} \Email{xyz@sample.edu}\\
 %  \addr Address}

 % Three or more authors with the same address:
 % \midlauthor{\Name{Author Name1} \Email{an1@sample.edu}\\
 %  \Name{Author Name2} \Email{an2@sample.edu}\\
 %  \Name{Author Name3} \Email{an3@sample.edu}\\
 %  \addr Address}


% Authors with different addresses:
% \midlauthor{\Name{Author Name1} \Email{abc@sample.edu}\\
% \addr Address 1
% \AND
% \Name{Author Name2} \Email{xyz@sample.edu}\\
% \addr Address 2
% }

%\footnotetext[1]{Contributed equally}

% More complicate cases, e.g. with dual affiliations and joint authorship
\midlauthor{\Name{{Dž}enan Zukić\nametag{$^{1}$}} \Email{dzenan.zukic@kitware.com}\\
\Name{Anne Haley\nametag{$^{1}$}} \Email{anne.haley@kitware.com}\\
% \Name{Daniel Chiquito\nametag{$^{1}$}} \Email{daniel.chiquito@kitware.com}\\
% \Name{Matt McCormick\nametag{$^{1}$}} \Email{matt.mccormick@kitware.com}\\
\Name{Curtis Lisle\nametag{$^{2}$}} \Email{clisle@knowledgevis.com}\\
\Name{Kilian Pohl\nametag{$^{3}$}} \Email{kilian.pohl@stanford.edu}\\
\Name{Hans Johnson\nametag{$^{4}$}} \Email{hans-johnson@uiowa.edu}\\
\Name{Aashish Chaudhary\nametag{$^{1}$}} \Email{aashish.chaudhary@kitware.com}\\
\addr $^{1}$ Kitware Inc., Carrboro, North Carolina, USA\\
\addr $^{2}$ KnowledgeVis LLC, Florida, USA\\
\addr $^{3}$ Department of Psychiatry \& Behavioral Sciences, Stanford University\\
\addr $^{4}$ Electrical and Computer Engineering, University of Iowa\\
% \vspace{-4mm}
}

\begin{document}

\maketitle

\begin{abstract}
This is a great paper and it has a concise abstract.
\end{abstract}

\begin{keywords}
quality control, quality assurance, deep learning, web interface.
\end{keywords}

\section{Introduction}

Discovery of new knowledge in medicine is sometimes accomplished by large, multi-center imaging studies. The success of these studies depends on the quality of images and the resulting measurements, regardless of the size of the study. Many studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Currently these procedures are often implemented by combining several software systems that are not designed to support Quality Assurance (QA) or Quality Control (QC) processes. Our Medical Image Quality Assurance (MIQA) system represents a design that facilitates collaboration and sharing. It incorporates a state-of-the-art deep learning component to improve the effectiveness of QC efforts unique to the needs of multi-center studies. The usefulness of this unique QC system is being tested by National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) project. NCANDA uses magnetic resonance images (MRIs) of the brain, so we focus on deep learning using head MRIs in this paper.

MIQA is a client-server web application based on \href{https://github.com/girder/girder}{Girder} and \href{https://www.django-rest-framework.org/}{django}. It uses \href{https://vuejs.org/}{Vue} and \href{https://vuetifyjs.com/}{Vuetify} for graphical user interface (GUI). For image processing we use \href{https://itk.org/}{Insight Toolkit (ITK)}. For neural network (NN) related operations we use \href{https://pytorch.org/}{PyTorch}, \href{https://monai.io/}{MONAI}, and \href{https://torchio.readthedocs.io/}{TorchIO}. Images are either imported or uploaded. During import, images are subjected to NN automatic quality assesement synchronously. After upload, images are auto-assesed asynchronously. Once the assesement is finished, the GUI is updated with the information. Automatic assesement helps human reviewers. Images which are not reviewed are available in a queue to tier one reviewers. They can mark it as good or questionable. Questionable images need to be reviewed by tier two reviewers who make a final decision. For an image to be marked bad, it needs to have either presence of at least one artifact indicated in the GUI, or a free-form text comment provided.

% I would like to mention that we use MRIQC~\cite{esteban2017mriqc}, but we should implement that before the paper deadline.

As far as we know, this is the first attempt at assessing image quality of 3D images. Previous studies used photographs~\cite{bosse2017deep,bianco2018use,hosu2020koniq}, retinal fundus images~\cite{yu2017image}, linguistic descriptions of images~\cite{hou2014blind}, or tried to improve image quality by e.g. reducing noise~\cite{higaki2019improvement}.

\section{Materials and Methods}

We use data from PREDICT-HD study~\cite{paulsen2014clinical}, which has manually assesed quality for 9475 structural (T$_1$, T$_2$, PD) brain MRIs.

\section{Results and Discussion}

This is where the content of your paper goes.  Some random notes:
\begin{itemize}
\item JMLR/PMLR uses natbib for references. For simplicity, here, \verb|\cite|  defaults to
  parenthetical citations, i.e. \verb|\citep|. You can of course also
  use \verb|\citet| for textual citations.
\item Note that the JMLR template provides many handy functionalities
such as \verb|\figureref| to refer to a figure, e.g. \figureref{fig:example},
\verb|\tableref| to refer to a table, e.g. \tableref{tab:example}.
\end{itemize}

\begin{table}[htbp]
 % The first argument is the label.
 % The caption goes in the second argument, and the table contents
 % go in the third argument.
\floatconts
  {tab:example}%
  {\caption{An Example Table}}%
  {\begin{tabular}{ll}
  \bfseries Dataset & \bfseries Result\\
  Data1 & 0.12345\\
  Data2 & 0.67890\\
  Data3 & 0.54321\\
  Data4 & 0.09876
  \end{tabular}}
\end{table}

\begin{figure}[htbp]
 % Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:example}
  {\caption{Example Image}}
  {\includegraphics[width=0.5\linewidth]{example-image}}
\end{figure}

% Acknowledgments---Will not appear in anonymized version
\midlacknowledgments{We thank a bunch of people.}

\bibliography{midl-samplebibliography}

\end{document}
